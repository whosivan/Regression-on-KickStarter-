{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "filename = 'KickStarter_Luther.csv'\n",
    "df = import_data(filename)\n",
    "df.sample(2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Data Based on Different Project Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KickStarter project is either success or live or fail\n",
    "df_success = df.loc[df.Status == 'success']\n",
    "df_fail = df.loc[df.Status == 'fail']\n",
    "df_live = df.loc[df.Status == 'live'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_success.describe()\n",
    "len(set(df_success.Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.pairplot(df_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "sns.heatmap(df_success.corr(), square=True, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a slight positive correlation between \n",
    "<br>- Number_of_Backer vs. Total_Pledged, </br>\n",
    "<br>- Goal vs. Total_Pledged, </br>\n",
    "<br>- and potentially some relationship between Total_Pledged vs.Goal</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#there are projects that has 253 different pledge options? There are.\n",
    "df_success.loc[df_success.Number_of_Pledge_Options >= 200];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Understand more about Location and Category cols before factorizing them into features.\n",
    "len(df_success.Category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to get the parent location (e.g. New York-NY --> NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parent_location(col):\n",
    "    \"\"\"get parent location of the location columns in KickStarter dataset\"\"\"\n",
    "    par_location = []\n",
    "    \n",
    "    for location in col.tolist():\n",
    "        par_location.append(location.split('-')[-1])\n",
    "    \n",
    "    print('length of strip location: %s' % len(par_location))\n",
    "    print('length of df location column: %s' % len(col))\n",
    "    \n",
    "    df_success['Par_Location'] = par_location\n",
    "    return df_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_parent_location(df_success.Location).sample(1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(df_success.Category.unique());\n",
    "print('length is: ' + str(len(df_success.Category.unique())));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The web scraped dataset contains categroy enlisted as sub-category rather than the main category, this follow funcion and dictionary were created to convert them into main category, so that features are minimized for further modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cat_dict = {'Art':['Ceramics', 'Conceptual Art', 'Digital Art', 'Illustration', 'Installations', \n",
    "       'Mixed Media', 'Painting', 'Performance Art', 'Public Art', 'Sculpture', 'Textiles', 'Video Art'], \n",
    "                 'Comics':['Anthologies', 'Comic Books', 'Events', 'Graphic Novels', 'Webcomics'],\n",
    "                 'Crafts':['Candles', 'Crochet', 'DIY', 'Embroidery','Glass', 'Knitting', 'Pottery',\n",
    "          'Printing', 'Quilts', 'Stationery', 'Taxidermy', 'Weaving', 'Woodworking'],\n",
    "                 'Dance':['Performances', 'Residencies', 'Spaces', 'Workshops'],\n",
    "                 'Design':['Architecture', 'Civic Design', 'Graphic Design', 'Interactive Design', \n",
    "                           'Product Design', 'Typography'],\n",
    "                 'Fashion':['Accessories', 'Apparel', 'Childrenswear' , 'Couture', \n",
    "                            'Footwear', 'Jewelry', 'Pet Fashion', 'Ready-to-wear'],\n",
    "                 'Action':['Action', 'Animation', 'Comedy', 'Documentary', 'Drama', 'Experimental', \n",
    "                           'Family', 'Fantasy', 'Festivals', 'Horror', 'Movie Theaters', 'Music Videos', \n",
    "                           'Narrative Film', 'Romance', 'Science Fiction', 'Shorts', 'Television', \n",
    "                           'Thrillers', 'Webseries'],\n",
    "                 'Food':['Bacon', 'Community Gardens', 'Cookbooks', 'Drinks', 'Events', \"Farmer's Markets\", \n",
    "                         'Farms', 'Food Trucks', 'Restaurants', 'Small Batch', 'Spaces', 'Vegan'],\n",
    "                 'Games':['Gaming Hardware', 'Live Games', 'Mobile Games', 'Playing Cards', 'Puzzles', \n",
    "                          'Tabletop Games', 'Video Games'],\n",
    "                 'Journalism':['Audio', 'Photo', 'Print', 'Video'],\n",
    "                 'Music':['Blues', 'Chiptune', 'Classical Music', 'Comedy', 'Country & Folk', \n",
    "                          'Electronic Music','Faith', 'Hip-Hop', 'Indie Rock', 'Jazz', 'Kids', \n",
    "                          'Latin', 'Metal', 'Pop', 'Punk', 'R&B', 'Rock', 'World Music'],\n",
    "                 'Photography':['Animals', 'Fine Art', 'Nature', 'People', 'Photobooks', 'Places'],\n",
    "                 'Publishing':['Academic', 'Anthologies', 'Art Books', 'Calendars', \"Children's Books\", \n",
    "                               'Comedy', 'Fiction', 'Letterpress', 'Literary Journals', \n",
    "                               'Nonfiction', 'Periodicals', 'Poetry', 'Radio & Podcasts',\n",
    "                               'Translations', 'Young Adult', 'Zines', 'Literary Spaces'],\n",
    "                 'Technology':['3D Printing', 'Apps', 'Camera Equipment', 'DIY Electronics', \n",
    "                                 'Fabrication Tools', 'Flight', 'Gadgets', 'Hardware', 'Makerspaces', \n",
    "                                 'Robots', 'Software', 'Sound', 'Space Exploration', 'Wearables', 'Web'],\n",
    "                 'Theater':['Comedy', 'Experimental', 'Festivals', 'Immersive', 'Musical', 'Plays', 'Spaces']\n",
    "                }\n",
    "\n",
    "def invert_dict(d):\n",
    "    return dict((v,k) for k in d for v in d[k])\n",
    "\n",
    "Category_dict = invert_dict(Cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_main_category(df, dict_):\n",
    "    df['Main_Category'] = df.Category.map(dict_)\n",
    "    return df\n",
    "\n",
    "map_main_category(df_success, Category_dict)\n",
    "df_success.fillna(0, inplace = True)\n",
    "df_success.sample(3, random_state = 42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reset all the 0s in the Main_Category to be the same as what Category is\n",
    "df_success.Main_Category[df_success['Main_Category'] == 0] = df_success.Category;\n",
    "len(df_success.Main_Category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all these success projects, how much more did they pledge comparing to their goals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With all these success projects, how much more did they pledge comparing to their goals?\n",
    "def get_pledge_difference(df, pledged, goal):\n",
    "    df['Pledged_Difference'] = df[pledged] - df[goal]\n",
    "    return df\n",
    "\n",
    "get_pledge_difference(df_success, 'Total_Pledged', 'Goal').head(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_success.loc[df_success.Pledged_Difference > 10000000];\n",
    "#14517 projects exceeded their goals by $500\n",
    "#4591 projects exceeded their goals by $5000\n",
    "#1053 projects exceeded their goals by $50000\n",
    "#120 projects exceeded their goals by $5000000\n",
    "#3 projects exceeded their goals by $50000000 \n",
    "#1 project that pledged over 10 mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_average_pledgeamount_per_project(df, pledged, numberofbacker):\n",
    "    df['Average_Pledge_Amount_byP'] = df[pledged] / df[numberofbacker]\n",
    "    return df\n",
    "\n",
    "#get_average_pledgeamount_per_project(df_success, 'Total_Pledged', 'Number_of_Backer').sample(3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reorder_col(df, colnames):\n",
    "    df = df[colnames]\n",
    "    return df\n",
    "\n",
    "colnames = ['Project_Name', 'Status', ' Inventor', 'Number_of_Backer', 'Total_Pledged', 'Goal', \n",
    "            'Par_Location', 'Location', 'Main_Category', 'Category', 'Number_of_Pledge_Options',\n",
    "            'Pledge_Detail', 'Pledged_Difference']\n",
    "df_success.rename(columns={' Inventor':'Inventor'})\n",
    "reorder_col(df_success, colnames).sample(1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby some colnums to visualize the dataset more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_groupby_barplot(df, coltogroupbyon, coltodoaggon, figurex, figurey, numberoftoprows):\n",
    "    \"\"\"returns a barplot with gorupby and aggregated columns and plot them based on user defined max number of rows.\"\"\"\n",
    "    temp_df = pd.DataFrame(df.groupby([coltogroupbyon], as_index=False)\\\n",
    "                         [coltodoaggon].sum())\n",
    "    temp_df.sort_values([coltodoaggon], ascending=False, inplace = True)\n",
    "    graph = temp_df.head(numberoftoprows).plot(x = coltogroupbyon, y =coltodoaggon, kind = 'bar', figsize = (figurex, figurey))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "graph_groupby_barplot(df_success, 'Par_Location', 'Pledged_Difference', 30, 10, 40)\n",
    "plt.xlabel('Location', fontsize = 25);\n",
    "plt.ylabel('Pledged $ Differences (Total Pledged - Goal)', fontsize = 25);\n",
    "plt.title('Pledged Difference by Location (Top 40)', fontsize = 28);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Location_by_AveragePledged = df_success.groupby(['Par_Location'], as_index=False)['Number_of_Backer', 'Total_Pledged'].sum()\n",
    "Location_by_AveragePledged['Amount_Pledged_by_Par_Location'] = Location_by_AveragePledged.Total_Pledged\\\n",
    "                                                                    - Location_by_AveragePledged.Number_of_Backer\n",
    "    \n",
    "Location_by_AveragePledged.sort_values(['Amount_Pledged_by_Par_Location'], ascending=False, inplace = True)\n",
    "Location_by_AveragePledged.head(10).plot(x = 'Par_Location', y = 'Amount_Pledged_by_Par_Location', kind = 'bar', figsize = (30, 10))\n",
    "plt.xlabel('Location', fontsize = 25);\n",
    "plt.ylabel('Amount $ Pledged/Project by Location', fontsize = 25);\n",
    "plt.title('Average Amount $ Pledged/Project by Location (Top 40)', fontsize = 28);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_groupby_barplot(df_success, 'Main_Category', 'Number_of_Backer', 30, 10, 40)\n",
    "plt.xlabel('Category', fontsize = 25);\n",
    "plt.ylabel('Number of Backers', fontsize = 25);\n",
    "plt.title('Number of Backers by Category (Top 40)', fontsize = 28);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine distribution of the Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_success['Total_Pledged'], \n",
    "             bins = 100,\n",
    "             kde_kws = {'color': '#e5ae38', 'label': 'KDE', 'clip':(0,50000)},\n",
    "             hist_kws = {'alpha': 0.25, \n",
    "                         'label': 'Total_Pledged', \n",
    "                         'edgecolor':'b', \n",
    "                         'linewidth':1, \n",
    "                         'color':'#4dd2ff',\n",
    "                         'range':[0,50000]},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE MODEL (V1)\n",
    "\n",
    "Feature using (X):\n",
    "- Number of Backer\n",
    "- Goal\n",
    "- Number of Pledged Option\n",
    "\n",
    "Feature predicting (Y):\n",
    "- Total Pledged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_dfs = df_success.copy()\n",
    "baseline_dfs.drop(columns=['Pledge_Detail', 'Location', 'Status', 'Category']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_dfs_col = ['Number_of_Backer', 'Goal', 'Number_of_Pledge_Options', 'Total_Pledged']\n",
    "baseline_dfs = reorder_col(baseline_dfs, baseline_dfs_col)\n",
    "baseline_dfs.sample(1, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_X = baseline_dfs.drop(columns=['Total_Pledged'])\n",
    "b_Y = baseline_dfs.Total_Pledged\n",
    "b_X, b_Y = np.array(b_X), np.array(b_Y)\n",
    "\n",
    "#split test and train dataset, hold out 20% of the data for final testing\n",
    "b_X_train, b_X_test, b_Y_train, b_Y_test = train_test_split(b_X, b_Y, test_size=0.2,random_state=2173)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 47)\n",
    "\n",
    "lm_baseline = [] #collect the validation results for base models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b_X_train, b_Y_train):\n",
    "    \n",
    "    X_train, Y_train = b_X_train[train_ind], b_Y_train[train_ind]\n",
    "    X_val, Y_val = b_X_train[val_ind], b_Y_train[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm_b = LinearRegression()\n",
    "\n",
    "    lm_b.fit(X_train, Y_train)\n",
    "    lm_baseline.append(lm_b.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "#Examine linear regression coefficient\n",
    "print('baseline linear regression model coefficient: %f' % lm_b.intercept_)\n",
    "print(set(zip((baseline_dfs.drop(columns=['Total_Pledged']).columns), lm_b.coef_)))\n",
    "print('Simple regression scores: %s' % lm_baseline)\n",
    "print('Simple mean cv r^2: %.3f +- %.3f' % (np.mean(lm_baseline),np.std(lm_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsm = smf.ols('Total_Pledged ~ Number_of_Backer + Goal + Number_of_Pledge_Options', data = df_success)\n",
    "fit1 = lsm.fit()\n",
    "print(fit1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#residual plot, funnel shape indicate collinearity\n",
    "#maybe possible to do transformation on the dataset\n",
    "sns.residplot(x = baseline_pred, y = b_Y_test-baseline_pred, data = df_success, scatter_kws={'alpha':0.2})\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual Plot for Baseline Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_pred = lm_b.predict(b_X_test)\n",
    "sns.jointplot(baseline_pred, b_Y_test, kind='regplot', size = 8)\n",
    "sns.set_context('talk')\n",
    "print(\"Linear Regression Baseline:\", r2_score(b_Y_test, baseline_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION MODEL WITH ADDITIONAL CATEGORICAL FEATUERS (V2)\n",
    "\n",
    "Feature using (X):\n",
    "- Number of Backer\n",
    "- Goal\n",
    "- Number of Pledged Option\n",
    "- Parent Location (convert using get_dummies)\n",
    "- Main Category (convert using get_dummies)\n",
    "\n",
    "Feature predicting (Y):\n",
    "- Total Pledged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_dummies_dfs = df_success.copy()\n",
    "add_dummies_dfs.drop(columns=['Project_Name', 'Pledge_Detail', 'Status', \n",
    "                              ' Inventor', 'Pledged_Difference'], inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_dummies_dfs_col = ['Par_Location', 'Main_Category', 'Number_of_Backer', \n",
    "                       'Goal', 'Number_of_Pledge_Options', 'Total_Pledged']\n",
    "add_dummies_dfs = reorder_col(add_dummies_dfs, add_dummies_dfs_col)\n",
    "add_dummies_dfs.rename(columns={' Inventor':'Inventor', \n",
    "                                'Par_Location':'Location', \n",
    "                                'Main_Category':'Category'}, inplace = True)\n",
    "add_dummies_dfs.sample(1, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dummy variable for Location and Category col\n",
    "add_dummies_dfs = pd.get_dummies(data = add_dummies_dfs, columns = ['Location', 'Category'])\n",
    "add_dummies_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b2_X = add_dummies_dfs.drop(columns=['Total_Pledged'])\n",
    "b2_Y = add_dummies_dfs.Total_Pledged\n",
    "b2_X, b2_Y = np.array(b2_X), np.array(b2_Y)\n",
    "\n",
    "#split test and train dataset, hold out 20% of the data for final testing\n",
    "b2_X_train, b2_X_test, b2_Y_train, b2_Y_test = train_test_split(b2_X, b2_Y, \n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Regression Model (5-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_v2_r2s = [] #collect the validation results for base models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b2_X_train, b2_Y_train):\n",
    "    \n",
    "    X_train, Y_train = b2_X_train[train_ind], b2_Y_train[train_ind]\n",
    "    X_val, Y_val = b2_X_train[val_ind], b2_Y_train[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm_v2 = LinearRegression()\n",
    "\n",
    "    lm_v2.fit(X_train, Y_train)\n",
    "    lm_v2_r2s.append(lm_v2.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "#Examine linear regression coefficient\n",
    "#print('(Dummy Variable Added) Simple regression model coefficient: %f' % lm_v2.intercept_)\n",
    "#print(set(zip((add_dummies_dfs.drop(columns=['Total_Pledged']).columns), lm_v2.coef_)))\n",
    "print('(Dummy Variable Added) Simple regression scores: %s' % lm_v2_r2s)\n",
    "print('Simple mean cv r^2: %.3f +- %.3f' % (np.mean(lm_v2_r2s),np.std(lm_v2_r2s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Simple Regression is not a good model, depending on the assigned random_state value, the model score can change dramatically, ranging from a well fit of 0.65 to -4000k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso, Ridge, and ElasticNet Model (5-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_lasso_r2s, cv_ridge_r2s, cv_EN_r2s = [], [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b2_X_train, b2_Y_train):\n",
    "    \n",
    "    X_train, y_train = b2_X_train[train_ind], b2_Y_train[train_ind]\n",
    "    X_val, y_val = b2_X_train[val_ind], b2_Y_train[val_ind] \n",
    "    \n",
    "    #feature scaling for lasso, ridge, EN\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    b2_X_test \n",
    "    \n",
    "    #Ridge regression\n",
    "    ridge_v2= Ridge(alpha = ridge_v2_grid_srh.best_params_['alpha'])\n",
    "    ridge_v2.fit(X_train_scaled, y_train)\n",
    "    cv_ridge_r2s.append(ridge_v2.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #lasso regression\n",
    "    lasso_v2= Lasso(alpha = lasso_v2_grid_srh.best_params_['alpha'])\n",
    "    lasso_v2.fit(X_train_scaled, y_train)\n",
    "    cv_lasso_r2s.append(lasso_v2.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #EN regression\n",
    "    EN_v2= ElasticNet(alpha = EN_v2_grid_srh.best_params_['alpha'])\n",
    "    EN_v2.fit(X_train_scaled, y_train)\n",
    "    cv_EN_r2s.append(EN_v2.score(X_val_scaled, y_val))\n",
    "\n",
    "    \n",
    "print('Ridge scores: ', cv_ridge_r2s, '\\n')\n",
    "print('Ridge mean cv r^2: %.3f +- %.3f' %(np.mean(cv_ridge_r2s),np.std(cv_ridge_r2s)))\n",
    "print('Lasso scores: ', cv_lasso_r2s, '\\n')\n",
    "print('Lasso mean cv r^2: %.3f +- %.3f' %(np.mean(cv_lasso_r2s),np.std(cv_lasso_r2s)))\n",
    "print('EN scores: ', cv_EN_r2s)\n",
    "print('EN mean cv r^2: %.3f +- %.3f' %(np.mean(cv_EN_r2s),np.std(cv_EN_r2s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use grid search to search for best alpha parameter for lasso, ridge, and EN\n",
    "def build_grid_search_est(model, X, y, cv=5, **params):\n",
    "    grid_est = GridSearchCV(model, param_grid=params, cv=cv)\n",
    "    grid_est.fit(X, y)\n",
    "    df = pd.DataFrame(grid_est.grid_scores_)\n",
    "    for param in params:\n",
    "        df[param] = df.parameters.apply(lambda val: val[param])\n",
    "        plt.semilogx(df.alpha, df.mean_validation_score)\n",
    "    grid_est.grid_scores_\n",
    "    return grid_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Lasso_v2 Grid Search\")\n",
    "lasso_v2_grid_srh = build_grid_search_est(Lasso(), \n",
    "                                          b2_X_train, \n",
    "                                          b2_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(1, 3, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"ridge_v2 Grid Search\")\n",
    "ridge_v2_grid_srh = build_grid_search_est(Ridge(), \n",
    "                                          b2_X_train, \n",
    "                                          b2_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(2, 4, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"ElasticNet_v2 Grid Search\")\n",
    "EN_v2_grid_srh = build_grid_search_est(ElasticNet(), \n",
    "                                       b2_X_train, \n",
    "                                       b2_Y_train, \n",
    "                                       cv=kf, \n",
    "                                       alpha=np.logspace(-2.5, 0.5, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scale the x_test for model eval\n",
    "scaler = StandardScaler()\n",
    "b2_X_test_scaled = scaler.fit_transform(b2_X_test)\n",
    "\n",
    "lm_v2_pred = lm_v2.predict(b2_X_test_scaled)\n",
    "print(\"Linear Regression:\", r2_score(b2_Y_test, lm_v2_pred))\n",
    "\n",
    "lasso_v2_pred = lasso_v2.predict(b2_X_test_scaled)\n",
    "print(\"Lasso Regression:\", r2_score(b2_Y_test, lasso_v2_pred))\n",
    "\n",
    "ridge_v2_pred = ridge_v2.predict(b2_X_test_scaled)\n",
    "print(\"Ridge Regression:\", r2_score(b2_Y_test, ridge_v2_pred))\n",
    "\n",
    "EN_v2_pred = EN_v2.predict(b2_X_test_scaled)\n",
    "print(\"ElasticNet Regression:\", r2_score(b2_Y_test, EN_v2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checking what parameter is elminated from regulazation\n",
    "\n",
    "models = {}\n",
    "\n",
    "models['ridgev2'] = ridge_v2\n",
    "models['lassov2'] = lasso_v2\n",
    "models['ENv3'] = EN_v2\n",
    "\n",
    "\n",
    "for name,model in models.items():\n",
    "    model.fit(b2_X_train,b2_Y_train)\n",
    "    print('Model: ' + name)\n",
    "    print(\"Score: \" + str(model.score(b2_X_train,b2_Y_train)))\n",
    "    sorted_features = sorted(zip(add_dummies_dfs.columns,model.coef_), key=lambda tup: abs(tup[1]), reverse=True)\n",
    "    for feature in sorted_features:\n",
    "        print(feature)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORD VECTORIZATION OF PROJECT NAMES AS ADDITIONAL FEATURES (V3) \n",
    "\n",
    "Feature using (X):\n",
    "- Number of Backer\n",
    "- Goal\n",
    "- Number of Pledged Option\n",
    "- Parent Location (convert using get_dummies)\n",
    "- Main Category (convert using get_dummies)\n",
    "- Project Name (Vectorized)\n",
    "- Inventor Name (Vectorized)\n",
    "\n",
    "Feature predicting (Y):\n",
    "- Total Pledged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_vec_df = df_success.copy()\n",
    "pre_vec_df.Project_Name = pre_vec_df.Project_Name.str.lower()\n",
    "pre_vec_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "vectorizer = TfidfVectorizer(stop_words=['a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from',\n",
    "                                         'has', 'he', 'in', 'is', 'its', 'it', 'of', 'on', 'that', 'the',\n",
    "                                         'to', 'was', 'were', 'will', 'with', 'she', 'mm', 'off'], min_df = 2, max_features = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace all the non-alphabatic characters in the project names to nothing, and drop all non-relevant cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_vec_df['Project_Name'].replace(r'([^a-z\\s])', '', regex=True, inplace=True)\n",
    "pre_vec_df.drop(columns = ['Location', 'Category', 'Pledge_Detail', 'Status', ' Inventor', 'Pledged_Difference'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_tfidf_vec = vectorizer.fit_transform(pre_vec_df.Project_Name).toarray()\n",
    "project_tfidf_df = pd.DataFrame(project_tfidf_vec, columns=list(vectorizer.vocabulary_.keys()))\n",
    "project_tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = [pre_vec_df, project_tfidf_df]\n",
    "project_vec_df = pd.concat(frame, axis = 1)\n",
    "project_vec_df.rename(columns={'Par_Location':'Location', 'Main_Category':'Category'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NLP without dummy\n",
    "project_vec_df_nodummy = project_vec_df.copy()\n",
    "project_vec_df_nodummy.drop(columns=['Project_Name', 'Location', 'Category'], inplace = True, axis = 1)\n",
    "project_vec_df_nodummy.fillna(0, inplace = True)\n",
    "project_vec_df_nodummy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now that we have vectorize the project name to top 2000 columns, lets also create the dummy variable for the Location and Category cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NLP with dummy\n",
    "project_vec_df = pd.get_dummies(data = project_vec_df, columns = ['Location', 'Category'])\n",
    "project_vec_df.drop(columns=['Project_Name'], inplace = True, axis = 1)\n",
    "project_vec_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split for NLP with dummy\n",
    "b3_X = project_vec_df.drop(columns=['Total_Pledged'])\n",
    "b3_Y = project_vec_df.Total_Pledged\n",
    "b3_X, b3_Y = np.array(b3_X), np.array(b3_Y)\n",
    "\n",
    "#split test and train dataset, hold out 20% of the data for final testing\n",
    "b3_X_train, b3_X_test, b3_Y_train, b3_Y_test = train_test_split(b3_X, b3_Y, \n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split for NLP without dummy\n",
    "b4_X = project_vec_df_nodummy.drop(columns=['Total_Pledged'])\n",
    "b4_Y = project_vec_df_nodummy.Total_Pledged\n",
    "b4_X, b4_Y = np.array(b4_X), np.array(b4_Y)\n",
    "\n",
    "#split test and train dataset, hold out 20% of the data for final testing\n",
    "b4_X_train, b4_X_test, b4_Y_train, b4_Y_test = train_test_split(b4_X, b4_Y, \n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso, Ridge, and EN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch to find best shrinking parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"ridge_v3 Grid Search\")\n",
    "ridge_v3_grid_srh = build_grid_search_est(Ridge(), \n",
    "                                          b3_X_train, \n",
    "                                          b3_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(-1, 3, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"EN_v3 Grid Search\")\n",
    "EN_v3_grid_srh = build_grid_search_est(ElasticNet(), \n",
    "                                          b3_X_train, \n",
    "                                          b3_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(-3, 1, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"lasso_v3 Grid Search\")\n",
    "lasso_v3_grid_srh = build_grid_search_est(Lasso(), \n",
    "                                          b3_X_train, \n",
    "                                          b3_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(-1, 3, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"ridge_v4 Grid Search\")\n",
    "ridge_v4_grid_srh = build_grid_search_est(Ridge(), \n",
    "                                          b4_X_train, \n",
    "                                          b4_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(-1, 3, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"lasso_v4 Grid Search\")\n",
    "lasso_v4_grid_srh = build_grid_search_est(Lasso(), \n",
    "                                          b4_X_train, \n",
    "                                          b4_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(-1, 3, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"EN_v4 Grid Search\")\n",
    "EN_v4_grid_srh = build_grid_search_est(ElasticNet(), \n",
    "                                          b4_X_train, \n",
    "                                          b4_Y_train, \n",
    "                                          cv=kf, \n",
    "                                          alpha=np.logspace(-3, 1, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('best ElasticNet_dummy alpha: %.3f' % EN_v3_grid_srh.best_params_['alpha'])\n",
    "print('best Lasso alpha_dummy: %.3f' % lasso_v3_grid_srh.best_params_['alpha'])\n",
    "print('best Ridge alpha_dummy: %.3f' % ridge_v3_grid_srh.best_params_['alpha'])\n",
    "print('best ElasticNet_nodummy alpha: %.3f' % EN_v4_grid_srh.best_params_['alpha'])\n",
    "print('best Lasso alpha_nodummy: %.3f' % lasso_v4_grid_srh.best_params_['alpha'])\n",
    "print('best Ridge alpha_nodummy: %.3f' % ridge_v4_grid_srh.best_params_['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fit with dummy variable df\n",
    "cv_lasso3_r2s, cv_ridge3_r2s, cv_EN3_r2s = [], [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b3_X_train, b3_Y_train):\n",
    "    \n",
    "    X_train, y_train = b3_X_train[train_ind], b3_Y_train[train_ind]\n",
    "    X_val, y_val = b3_X_train[val_ind], b3_Y_train[val_ind] \n",
    "    \n",
    "    #feature scaling for lasso, ridge, EN\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    #Ridge regression\n",
    "    ridge_v3= Ridge(alpha = ridge_v3_grid_srh.best_params_['alpha'])\n",
    "    ridge_v3.fit(X_train_scaled, y_train)\n",
    "    cv_ridge3_r2s.append(ridge_v3.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #lasso regression\n",
    "    lasso_v3= Lasso(alpha = lasso_v3_grid_srh.best_params_['alpha'])\n",
    "    lasso_v3.fit(X_train_scaled, y_train)\n",
    "    cv_lasso3_r2s.append(lasso_v3.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #EN regression\n",
    "    EN_v3= ElasticNet(alpha = EN_v3_grid_srh.best_params_['alpha'])\n",
    "    EN_v3.fit(X_train_scaled, y_train)\n",
    "    cv_EN3_r2s.append(EN_v3.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fit without dummy variable df\n",
    "cv_lasso4_r2s, cv_ridge4_r2s, cv_EN4_r2s = [], [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b4_X_train, b4_Y_train):\n",
    "    \n",
    "    X_train, y_train = b4_X_train[train_ind], b4_Y_train[train_ind]\n",
    "    X_val, y_val = b4_X_train[val_ind], b4_Y_train[val_ind] \n",
    "    \n",
    "    #feature scaling for lasso, ridge, EN\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    #Ridge regression\n",
    "    ridge_v4= Ridge(alpha = ridge_v4_grid_srh.best_params_['alpha'])\n",
    "    ridge_v4.fit(X_train_scaled, y_train)\n",
    "    cv_ridge4_r2s.append(ridge_v4.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #lasso regression\n",
    "    lasso_v4= Lasso(alpha = lasso_v4_grid_srh.best_params_['alpha'])\n",
    "    lasso_v4.fit(X_train_scaled, y_train)\n",
    "    cv_lasso4_r2s.append(lasso_v4.score(X_val_scaled, y_val))\n",
    "    \n",
    "    #EN regression\n",
    "    EN_v4= ElasticNet(alpha = EN_v4_grid_srh.best_params_['alpha'])\n",
    "    EN_v4.fit(X_train_scaled, y_train)\n",
    "    cv_EN4_r2s.append(EN_v4.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Ridge_dummy scores: ', cv_ridge3_r2s, '\\n')\n",
    "print('Ridge_dummy mean cv r^2: %.3f +- %.3f' %(np.mean(cv_ridge3_r2s),np.std(cv_ridge3_r2s)))\n",
    "print('Lasso_dummy scores: ', cv_lasso3_r2s, '\\n')\n",
    "print('Lasso_dummy mean cv r^2: %.3f +- %.3f' %(np.mean(cv_lasso3_r2s),np.std(cv_lasso3_r2s)))\n",
    "print('EN_dummy scores: ', cv_EN3_r2s)\n",
    "print('EN_dummy mean cv r^2: %.3f +- %.3f' %(np.mean(cv_EN3_r2s),np.std(cv_EN3_r2s)))\n",
    "\n",
    "print('Ridge_nodummy scores: ', cv_ridge4_r2s, '\\n')\n",
    "print('Ridge_nodummy mean cv r^2: %.3f +- %.3f' %(np.mean(cv_ridge4_r2s),np.std(cv_ridge4_r2s)))\n",
    "print('Lasso_nodummy scores: ', cv_lasso4_r2s, '\\n')\n",
    "print('Lasso_nodummy mean cv r^2: %.3f +- %.3f' %(np.mean(cv_lasso4_r2s),np.std(cv_lasso4_r2s)))\n",
    "print('EN_nodummy scores: ', cv_EN4_r2s)\n",
    "print('EN_nodummy mean cv r^2: %.3f +- %.3f' %(np.mean(cv_EN4_r2s),np.std(cv_EN4_r2s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "b3_X_test_scaled = scaler.fit_transform(b3_X_test)\n",
    "b4_X_test_scaled = scaler.fit_transform(b4_X_test)\n",
    "\n",
    "lasso_v3_pred = lasso_v3.predict(b3_X_test_scaled)\n",
    "print(\"Lasso Regression:\", r2_score(b3_Y_test, lasso_v3_pred))\n",
    "ridge_v3_pred = ridge_v3.predict(b3_X_test_scaled)\n",
    "print(\"Ridge Regression:\", r2_score(b3_Y_test, ridge_v3_pred))\n",
    "EN_v3_pred = EN_v3.predict(b3_X_test_scaled)\n",
    "print(\"ElasticNet Regression:\", r2_score(b3_Y_test, EN_v3_pred))\n",
    "lasso_v4_pred = lasso_v4.predict(b4_X_test_scaled)\n",
    "print(\"Lasso_nodummy Regression:\", r2_score(b4_Y_test, lasso_v4_pred))\n",
    "ridge_v4_pred = ridge_v4.predict(b4_X_test_scaled)\n",
    "print(\"Ridge_nodummy Regression:\", r2_score(b4_Y_test, ridge_v4_pred))\n",
    "EN_v4_pred = EN_v3.predict(b3_X_test_scaled)\n",
    "print(\"ElasticNet_nodummy Regression:\", r2_score(b4_Y_test, EN_v4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NLP + Dummy feature selection\n",
    "models = {}\n",
    "\n",
    "models['ridgev3'] = ridge_v3\n",
    "models['lassov3'] = lasso_v3\n",
    "models['ENv3'] = EN_v3\n",
    "\n",
    "for name,model in models.items():\n",
    "    model.fit(b3_X_train,b3_Y_train)\n",
    "    print('Model: ' + name)\n",
    "    print(\"Score: \" + str(model.score(b3_X_train,b3_Y_train)))\n",
    "    sorted_features = sorted(zip(project_vec_df.columns,model.coef_), key=lambda tup: abs(tup[1]), reverse=True)\n",
    "    for feature in sorted_features:\n",
    "        print(feature)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lassov3fs = smf.ols(\"Total_Pledged ~ Location_NV + Number_of_Backer + Goal + blood + Category_Comics + \\\n",
    "Location_MA + Location_TN + media + Category_Art + platform + Location_France + Category_Food + comics +\\\n",
    "Category_Publishing + bbq + money + photobook + desert + radio\", data = project_vec_df)\n",
    "lassov3fs1 = lassov3fs.fit()\n",
    "print(lassov3fs1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#residual plot\n",
    "sns.residplot(x = lasso_v3_pred, y = b3_Y_test-lasso_v3_pred, data = add_dummies_dfs, scatter_kws={'alpha':0.2})\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual Plot for Baseline Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models['ridgev4'] = ridge_v4\n",
    "models['lassov4'] = lasso_v4\n",
    "models['ENv4'] = EN_v4\n",
    "\n",
    "for name,model in models.items():\n",
    "    model.fit(b4_X_train,b4_Y_train)\n",
    "    print('Model: ' + name)\n",
    "    print(\"Score: \" + str(model.score(b4_X_train,b4_Y_train)))\n",
    "    sorted_features = sorted(zip(project_vec_df_nodummy.columns,model.coef_), key=lambda tup: abs(tup[1]), reverse=True)\n",
    "    for feature in sorted_features:\n",
    "        print(feature)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lassov4fs = smf.ols(\"Total_Pledged ~ radio + desert + photobook + \\\n",
    "money + bbq + comics + memory + media + platform + experiment + blood + Number_of_Backer +\\\n",
    "Goal + Number_of_Pledge_Options\", data = project_vec_df_nodummy)\n",
    "lassov4fs1 = lassov4fs.fit()\n",
    "print(lassov4fs1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with dummy top 5(out of 1000)\n",
    "weights = np.asarray(project_tfidf_vec.mean(axis=0)).ravel().tolist()\n",
    "counts_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': weights})\n",
    "top5_feature = counts_df.sort_values(by='weight', ascending=False).head(5)\n",
    "top5_feature\n",
    "\n",
    "sns.barplot(x=top5_feature.term, y=top5_feature.weight, data=top5_feature)\n",
    "plt.xlabel('Most Associated Vocabulary')\n",
    "plt.ylabel('TFIDF Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with dummy last 5(out of 1000)\n",
    "tail5_feature = counts_df.sort_values(by='weight', ascending=True).head(5)\n",
    "tail5_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "weights = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': tvec.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#residual plot\n",
    "sns.residplot(x = lasso_v4_pred, y = b4_Y_test-lasso_v4_pred, data = project_vec_df_nodummy, scatter_kws={'alpha':0.2})\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual Plot for lasso final Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to high colinearity of the dataset, trying to GBR and RF as option to see how the model will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBM_baseline, rf_baseline = [], [] #collect the validation results for base models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b_X_train, b_Y_train):\n",
    "    \n",
    "    X_train, Y_train = b_X_train[train_ind], b_Y_train[train_ind]\n",
    "    X_val, Y_val = b_X_train[val_ind], b_Y_train[val_ind] \n",
    "    \n",
    "    # RF \n",
    "    rf_b = RandomForestRegressor(n_estimators=800, max_features=3)\n",
    "    rf_b.fit(X_train, Y_train)\n",
    "    rf_baseline.append(rf_b.score(X_val, Y_val))\n",
    "    \n",
    "    # GBM\n",
    "    gbm_b = GradientBoostingRegressor(n_estimators=100, max_depth=3, learning_rate=.1)\n",
    "    gbm_b.fit(X_train, Y_train)\n",
    "    GBM_baseline.append(gbm_b.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "#Examine baseline RF Model:\n",
    "print('Baseline RF scores: %s' % rf_baseline)\n",
    "print('Baseline RF R^2: %.3f +- %.3f' % (np.mean(rf_baseline),np.std(rf_baseline)))\n",
    "print('Baseline GBM scores: %s' % GBM_baseline)\n",
    "print('Baseline GBM R^2: %.3f +- %.3f' % (np.mean(GBM_baseline),np.std(GBM_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dummy Variable Feature added in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBM_v2_r2s, rf_v2_r2s = [], [] #collect the validation results for base models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b2_X_train, b2_Y_train):\n",
    "    \n",
    "    X_train, Y_train = b2_X_train[train_ind], b2_Y_train[train_ind]\n",
    "    X_val, Y_val = b2_X_train[val_ind], b2_Y_train[val_ind] \n",
    "    \n",
    "    # RF \n",
    "    rf_v2 = RandomForestRegressor(n_estimators=800, max_features=3)\n",
    "    rf_v2.fit(X_train, Y_train)\n",
    "    rf_v2_r2s.append(rf_v2.score(X_val, Y_val))\n",
    "    \n",
    "    # GBM\n",
    "    gbm_v2 = GradientBoostingRegressor(n_estimators=100, max_depth=3, learning_rate=.1)\n",
    "    gbm_v2.fit(X_train, Y_train)\n",
    "    GBM_v2_r2s.append(gbm_v2.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "#Examine v2(just dummy) RF Model:\n",
    "print('Baseline RF scores: %s' % rf_v2_r2s)\n",
    "print('Baseline RF R^2: %.3f +- %.3f' % (np.mean(rf_v2_r2s),np.std(rf_v2_r2s)))\n",
    "print('Baseline GBM scores: %s' % GBM_v2_r2s)\n",
    "print('Baseline GBM R^2: %.3f +- %.3f' % (np.mean(GBM_v2_r2s),np.std(GBM_v2_r2s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBM_v3_r2s, rf_v3_r2s = [], [] #collect the validation results for base models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b3_X_train, b3_Y_train):\n",
    "    \n",
    "    X_train, Y_train = b3_X_train[train_ind], b3_Y_train[train_ind]\n",
    "    X_val, Y_val = b3_X_train[val_ind], b3_Y_train[val_ind] \n",
    "    \n",
    "    # RF \n",
    "    rf_v3 = RandomForestRegressor(n_estimators=800, max_features=3)\n",
    "    rf_v3.fit(X_train, Y_train)\n",
    "    rf_v3_r2s.append(rf_v3.score(X_val, Y_val))\n",
    "    \n",
    "    # GBM\n",
    "    gbm_v3 = GradientBoostingRegressor(n_estimators=100, max_depth=3, learning_rate=.1)\n",
    "    gbm_v3.fit(X_train, Y_train)\n",
    "    GBM_v3_r2s.append(gbm_v3.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "#Examine v3(NLP wtih dummy) RF Model:\n",
    "print('Baseline RF scores: %s' % rf_v3_r2s)\n",
    "print('Baseline RF R^2: %.3f +- %.3f' % (np.mean(rf_v3_r2s),np.std(rf_v3_r2s)))\n",
    "print('Baseline GBM scores: %s' % GBM_v3_r2s)\n",
    "print('Baseline GBM R^2: %.3f +- %.3f' % (np.mean(GBM_v3_r2s),np.std(GBM_v3_r2s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBM_v4_r2s, rf_v4_r2s = [], [] #collect the validation results for base models\n",
    "\n",
    "for train_ind, val_ind in kf.split(b4_X_train, b4_Y_train):\n",
    "    \n",
    "    X_train, Y_train = b4_X_train[train_ind], b4_Y_train[train_ind]\n",
    "    X_val, Y_val = b4_X_train[val_ind], b4_Y_train[val_ind] \n",
    "    \n",
    "    # RF \n",
    "    rf_v4 = RandomForestRegressor(n_estimators=800, max_features=3)\n",
    "    rf_v4.fit(X_train, Y_train)\n",
    "    rf_v4_r2s.append(rf_v4.score(X_val, Y_val))\n",
    "    \n",
    "    # GBM\n",
    "    gbm_v4 = GradientBoostingRegressor(n_estimators=100, max_depth=3, learning_rate=.1)\n",
    "    gbm_v4.fit(X_train, Y_train)\n",
    "    GBM_v4_r2s.append(gbm_v4.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "#Examine v3(NLP wtih dummy) RF Model:\n",
    "print('Baseline RF scores: %s' % rf_v4_r2s)\n",
    "print('Baseline RF R^2: %.3f +- %.3f' % (np.mean(rf_v4_r2s),np.std(rf_v4_r2s)))\n",
    "print('Baseline GBM scores: %s' % GBM_v4_r2s)\n",
    "print('Baseline GBM R^2: %.3f +- %.3f' % (np.mean(GBM_v4_r2s),np.std(GBM_v4_r2s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "b3_X_test_scaled = scaler.fit_transform(b3_X_test)\n",
    "b4_X_test_scaled = scaler.fit_transform(b4_X_test)\n",
    "\n",
    "lasso_v3_pred = lasso_v3.predict(b3_X_test_scaled)\n",
    "print(\"Lasso Regression:\", r2_score(b3_Y_test, lasso_v3_pred))\n",
    "ridge_v3_pred = ridge_v3.predict(b3_X_test_scaled)\n",
    "print(\"Ridge Regression:\", r2_score(b3_Y_test, ridge_v3_pred))\n",
    "EN_v3_pred = EN_v3.predict(b3_X_test_scaled)\n",
    "print(\"ElasticNet Regression:\", r2_score(b3_Y_test, EN_v3_pred))\n",
    "lasso_v4_pred = lasso_v4.predict(b4_X_test_scaled)\n",
    "print(\"Lasso_nodummy Regression:\", r2_score(b4_Y_test, lasso_v4_pred))\n",
    "ridge_v4_pred = ridge_v4.predict(b4_X_test_scaled)\n",
    "print(\"Ridge_nodummy Regression:\", r2_score(b4_Y_test, ridge_v4_pred))\n",
    "EN_v4_pred = EN_v3.predict(b3_X_test_scaled)\n",
    "print(\"ElasticNet_nodummy Regression:\", r2_score(b4_Y_test, EN_v4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
